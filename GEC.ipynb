{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <center> GEC\n",
    "GEC pour tester les modèles et les métriques en sortie.\n",
    "Implémentation de la métrique GLEU ?\n",
    "Utilisation du modèle BART ? Ou de l'implémentation de BERT ? Ou de l'implémentation de GPT-2 ? Ou de l'implémentation de T5 ? Ou de l'implémentation de GPT-3 ?\n",
    "\n",
    "Implémentation d'un modèle GEC en simulation de la pipeline.\n",
    "\n",
    "\n",
    "Modèle T5:\n",
    "https://huggingface.co/vennify/t5-base-grammar-correction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7600c773045bf8b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alors, de ce que j'ai vu on peut utiliser des modèles text to text comme le modèle transformer T5 de google ou le modèle BART de facebook.\n",
    "BART : https://ai.meta.com/research/publications/bart-denoising-sequence-to-sequence-pre-training-for-natural-language-generation-translation-and-comprehension/\n",
    "T5 : https://blog.research.google/2020/02/exploring-transfer-learning-with-t5.html\n",
    "En se référant au SOTA de la tâche GEC : on peut considérer les modèles transformer comme étant les meilleurs modèles pour la tâche GEC.\n",
    "https://arxiv.org/pdf/2106.03830.pdf\n",
    "https://aclanthology.org/2022.coling-1.246/\n",
    "https://dl.acm.org/doi/abs/10.1145/3474840\n",
    "\n",
    "https://scholar.google.com/scholar?hl=fr&as_sdt=0%2C5&q=gec+grammatical+error+correction&btnG=&oq=GEC\n",
    "\n",
    "Aussi différents concours on eu lieu, comme le BEA :\n",
    "en 2019 le BEA aborde la tâche GEC. https://www.cl.cam.ac.uk/research/nl/bea2019st/\n",
    "**https://competitions.codalab.org/competitions/20228#results**\n",
    "https://aclanthology.org/W19-4406.pdf\n",
    "\n",
    "SOTA 2020 : grammarly avec GECTor : https://arxiv.org/pdf/2005.12592v2.pdf   https://github.com/grammarly/gector\n",
    "best SOTA ? : https://aclanthology.org/2022.naacl-main.143/\n",
    "\n",
    "\n",
    "huggingface pretrained : https://huggingface.co/transformers/v3.3.1/pretrained_models.html\n",
    "\n",
    "https://huggingface.co/docs/transformers/model_doc/t5\n",
    "\n",
    "https://huggingface.co/docs/transformers/model_doc/bart\n",
    "papiers bart : https://arxiv.org/abs/2005.11849\n",
    "\n",
    "BTS TTT :  https://aclanthology.org/2021.wat-1.10.pdf\n",
    "\n",
    "https://aclanthology.org/W19-4413.pdf\n",
    "LLM GEC : https://aclanthology.org/2021.emnlp-main.611.pdf\n",
    "\n",
    "\n",
    "BERT\n",
    "https://sunilchomal.github.io/GECwBERT/\n",
    "https://huggingface.co/bert-base-uncased\n",
    "\n",
    "\n",
    "GPT3 https://aclanthology.org/2023.bea-1.18.pdf\n",
    "https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\n",
    "https://arxiv.org/abs/2303.13648\n",
    "\n",
    "\n",
    "GEC VIDEO (BANGER0): https://aclanthology.org/2022.naacl-main.143.mp4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbd5880dc014f9e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation avec F0.5, GLUE, BLUE, ROUGE, exact match..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfbd9a659641c708"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Imports libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52d6dfdbe3f9505b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch, os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datetime import date\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "from happytransformer import HappyTextToText, TTSettings\n",
    "from evaluate import load\n",
    "#!pip3 install bert-score\n",
    "bertscore = load(\"bertscore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:13:52.900139500Z",
     "start_time": "2023-12-12T03:13:39.530331Z"
    }
   },
   "id": "a042e2fcde0a16c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Import des données"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb8a7173253b695a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class ASR_Dataset(Dataset):\n",
    "    def __init__(self, path, text=None):\n",
    "        \n",
    "        self.sentences = []\n",
    "        \n",
    "        if text is not None:\n",
    "            self.sentences.append(text.strip())\n",
    "        else:\n",
    "            self.path = path\n",
    "            self.files = os.listdir(path)\n",
    "            for file in self.files:\n",
    "                with open(path + '\\\\' + file, 'r', encoding='utf-8') as file:\n",
    "                    for line in file:\n",
    "                        self.sentences.append(line.strip())\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        transcript = self.sentences[idx]\n",
    "        return transcript\n",
    "\n",
    "\n",
    "def load_jfleg_dataset(path='data\\\\', text=None):\n",
    "    jfleg_dataset = load_dataset(\"jfleg\", \"test\", split=\"test\", cache_dir=path)\n",
    "    jfleg_Dataloader = DataLoader(jfleg_dataset, batch_size=1)\n",
    "    \n",
    "    print(\"Number of samples:\", len(jfleg_dataset))\n",
    "\n",
    "    sample_meta0 = jfleg_Dataloader.dataset[0]\n",
    "    print(\"\"\"\n",
    "    Transcript n°0 :\n",
    "\n",
    "    Path audio: {}\n",
    "    Sentence: {}\n",
    "    Corrections: {}\n",
    "    \"\"\".format(path, sample_meta0['sentence'], sample_meta0['corrections']))\n",
    "    \n",
    "    return jfleg_Dataloader\n",
    "\n",
    "def process_jfleg(data, model='T5'):\n",
    "    sentence = data['sentence']\n",
    "    corrections = data['corrections']\n",
    "    \n",
    "    return sentence[0], 0, corrections\n",
    "\n",
    "\n",
    "def load_ASR_dataset(path='data\\\\ASR', text=None, dataset=ASR_Dataset):\n",
    "    ASR_Dataset = dataset(path, text)\n",
    "    ASR_Dataloader = DataLoader(ASR_Dataset, batch_size=1)\n",
    "    \n",
    "    print(\"Number of samples:\", len(ASR_Dataset))\n",
    "    \n",
    "    sample_meta0 = ASR_Dataset\n",
    "    print(\"\"\"\n",
    "    Transcript n°0 :\n",
    "    \n",
    "    Transcript : {}\n",
    "    \"\"\".format(*sample_meta0))\n",
    "    \n",
    "    return ASR_Dataloader\n",
    "\n",
    "def process_ASR(data, model='T5'):\n",
    "    return data[0], 0, None\n",
    "\n",
    "def evaluate_jfleg(input, labels, model, tokenizer):\n",
    "    results = []\n",
    "    bert_scores = []\n",
    "    for correction in labels:\n",
    "        if load('exact_match').compute(references=correction, predictions=[input])['exact_match'] == 1:\n",
    "            return correction, 5, None\n",
    "        \n",
    "        bert_scores.append(bertscore.compute(predictions=[input], references=correction, lang=\"en\"))\n",
    "        input_ids = tokenizer.encode(\"stsb sentence 1: \"+input+\" sentence 2: \"+correction[0], return_tensors=\"pt\").to(\"cuda\")\n",
    "        stsb_ids = model.generate(input_ids)\n",
    "        stsb = tokenizer.decode(stsb_ids[0],skip_special_tokens=True)\n",
    "        results.append(float(stsb))\n",
    "    \n",
    "    max_arg = results.index(max(results))\n",
    "    max_score = results[max_arg]\n",
    "    \n",
    "    max_bert = {}\n",
    "    for scores in bert_scores:\n",
    "        for key, value in scores.items():\n",
    "            if key != \"hashcode\":\n",
    "                if key not in max_bert:\n",
    "                    max_bert[key] = value\n",
    "                else:\n",
    "                    max_bert[key] = max(max_bert[key], value)\n",
    "    \n",
    "    return labels[max_arg], max_score, max_bert\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T04:58:53.094756500Z",
     "start_time": "2023-12-12T04:58:53.059067200Z"
    }
   },
   "id": "5edb74092353347e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def GEC(text:str = None, model='T5', output_folder='output', dataset='ASR'):\n",
    "    pipeline = \"/pipeline/\" if text is not None else \"/\"\n",
    "    correction_folder = output_folder + pipeline + model + '_' + dataset\n",
    "    correction_file =f'{correction_folder}/output_GEC.{date.today()}.txt'\n",
    "    verification = f'{correction_folder}/Verification.{date.today()}.txt'\n",
    "    vard = f'{correction_folder}/vard.{date.today()}.txt'\n",
    "    os.makedirs(correction_folder, exist_ok=True)\n",
    "    \n",
    "    #TQDM loader\n",
    "    try:\n",
    "        function = \"load_\" + dataset + \"_dataset\"\n",
    "        dataloader = eval(function)(text=text)\n",
    "        dataloader_tqdm = tqdm(dataloader, total=len(dataloader))\n",
    "        \n",
    "        process_function = \"process_\" + dataset\n",
    "    except Exception as e:\n",
    "        raise ValueError(f'Unknown dataset {dataset}{e}')\n",
    "    \n",
    "    print(f'Generating corrections for {dataset} with {model} in {correction_folder}')\n",
    "    if model == 'T5':\n",
    "        T5 = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\n",
    "        args = TTSettings(num_beams=5, min_length=1, max_length=100)\n",
    "    \n",
    "    with open(correction_file, 'w', encoding='utf-8') as file:\n",
    "        file.write('')\n",
    "        \n",
    "    if dataset == 'jfleg':\n",
    "        with open(verification, 'w', encoding='utf-8') as file:\n",
    "                    file.write('')\n",
    "        with open(vard, 'w', encoding='utf-8') as file:\n",
    "                    file.write('')\n",
    " \n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-base', model_max_length=512)\n",
    "    model_evaluation = T5ForConditionalGeneration.from_pretrained('t5-base').to(\"cuda\")\n",
    "    mean_evaluation_score = 0\n",
    "    mean_bert = {}\n",
    "    result = \"\"\n",
    "    for i, data in enumerate(dataloader_tqdm):\n",
    "        (sentence, out, extra) = eval(process_function)(data, model=model)\n",
    "        \n",
    "        if out == 1:\n",
    "            dataloader_tqdm.set_postfix({'status': 'Skipped', 'ID': i})\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            #Passage du transcript dans le modèle\n",
    "            if model == 'T5':\n",
    "                result = T5.generate_text(\"grammar:\" + sentence, args=args).text\n",
    "                with open(correction_file, 'a', encoding='utf-8') as file:\n",
    "                    file.write(result + '\\n')\n",
    "                if dataset == 'jfleg':\n",
    "                    with open(vard, 'a', encoding='utf-8') as file:\n",
    "                        file.write(sentence + '\\n')\n",
    "            elif model == 'BART':\n",
    "                result = ''\n",
    "            else:\n",
    "                raise ValueError(f'Unknown model {model}')\n",
    "            \n",
    "            dataloader_tqdm.set_postfix()\n",
    "\n",
    "        except Exception as e:\n",
    "            dataloader_tqdm.set_postfix({'status': 'Error', 'ID': i})\n",
    "            raise e \n",
    "        \n",
    "        # Validation and test with JFLEG\n",
    "        if extra is not None:\n",
    "            best_correction, t5sim, bert_score = evaluate_jfleg(sentence, extra, model_evaluation, tokenizer)\n",
    "            mean_evaluation_score += t5sim\n",
    "            \n",
    "            with open(verification, 'a', encoding='utf-8') as file:\n",
    "                file.write(best_correction[0] + '\\n')\n",
    "            \n",
    "            if bert_score is not None:\n",
    "                for key, value in bert_score.items():\n",
    "                    val = value[0]\n",
    "                    if key not in mean_bert:\n",
    "                        mean_bert[key] = val\n",
    "                    else:\n",
    "                        mean_bert[key] += val\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    mean_evaluation_score /= len(dataloader)\n",
    "    result_test = f'Mean evaluation score: {mean_evaluation_score}\\n'\n",
    "    \n",
    "    for key, value in mean_bert.items():\n",
    "        mean_bert[key] /= len(dataloader)\n",
    "        result_test += f'Mean {key} score: {mean_bert[key]}\\n'\n",
    "    \n",
    "    return result if result != \"\" else result_test\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T04:58:53.828630100Z",
     "start_time": "2023-12-12T04:58:53.816668100Z"
    }
   },
   "id": "45b5c48f45f4e44b"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 21\n",
      "\n",
      "    Transcript n°0 :\n",
      "    \n",
      "    Transcript : She don't like to eat vegetables.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "892df34c417b4d04a5e38301aab2dc33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating corrections for ASR with T5 in output/T5_ASR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/06/2023 23:58:04 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "HappyTextToText.eval() missing 1 required positional argument: 'input_filepath'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mGEC\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mT5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moutput\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mASR\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[32], line 28\u001B[0m, in \u001B[0;36mGEC\u001B[1;34m(model, output_folder, dataset)\u001B[0m\n\u001B[0;32m     26\u001B[0m mean_evaluation_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     27\u001B[0m mean_evaluation_accuracy \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mT5\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader_tqdm):\n\u001B[0;32m     32\u001B[0m     (sentence, out, extra) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28meval\u001B[39m(process_function)(data, model\u001B[38;5;241m=\u001B[39mmodel)\n",
      "\u001B[1;31mTypeError\u001B[0m: HappyTextToText.eval() missing 1 required positional argument: 'input_filepath'"
     ]
    }
   ],
   "source": [
    "# GEC(model='T5', output_folder='output', dataset='ASR')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T04:58:23.902041700Z",
     "start_time": "2023-12-07T04:57:54.072104700Z"
    }
   },
   "id": "f53a6e0cb62d5ebc"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 748\n",
      "\n",
      "    Transcript n°0 :\n",
      "\n",
      "    Path audio: data\\\n",
      "    Sentence: New and new technology has been introduced to the society .\n",
      "    Corrections: ['New technology has been introduced to society .', 'New technology has been introduced into the society .', 'Newer and newer technology has been introduced into society .', 'Newer and newer technology has been introduced to the society .']\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/748 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19a9948ded494e47b2db61092a0a4ed7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating corrections for jfleg with T5 in output/T5_jfleg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/11/2023 23:59:26 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "12/11/2023 23:59:33 - INFO - happytransformer.happy_transformer -   Moving model to cuda:0\n",
      "12/11/2023 23:59:33 - INFO - happytransformer.happy_transformer -   Initializing a pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean evaluation score: 4.856417112299462\n",
      "Mean precision score: 0.7269314780114169\n",
      "Mean recall score: 0.7353363115201021\n",
      "Mean f1 score: 0.7309015628328935\n"
     ]
    }
   ],
   "source": [
    "# GEC(model='T5', output_folder='output', dataset='jfleg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T05:37:14.209356900Z",
     "start_time": "2023-12-12T04:59:19.094421300Z"
    }
   },
   "id": "514330ac0fc15077"
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://aclanthology.org/P17-1074.pdf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "473c89433f866321"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Autres tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63092227cb1eca35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jfleg training:\n",
    "https://huggingface.co/vennify/t5-base-grammar-correction\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed3b228fa9399e7c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# model_b = T5ForConditionalGeneration.from_pretrained('t5-small').to(\"cuda\")\n",
    "# stsb_sentence_1 = preprocess_text\n",
    "# stsb_sentence_2 = output\n",
    "# input_ids = tokenizer.encode(\"stsb sentence 1: \"+stsb_sentence_1+\" sentence 2: \"+stsb_sentence_2, return_tensors=\"pt\").to(\"cuda\")\n",
    "# stsb_ids = model_b.generate(input_ids)\n",
    "# stsb = tokenizer.decode(stsb_ids[0],skip_special_tokens=True)\n",
    "# print(stsb)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:03:33.541295900Z",
     "start_time": "2023-12-03T22:03:31.450541Z"
    }
   },
   "id": "c05518eae2bd36be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
