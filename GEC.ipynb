{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <center> GRAMMATICAL ERROR CORRECTION\n",
    "\n",
    "Notebook de test et d'implémentation de modèles de GEC.\n",
    "Pour notre GEC nous avons besoin d'un modèle qui prend en entrée un texte et qui renvoie un texte corrigé. Ce genre de modèles s'apparentent à des modèles seq2seq."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "197498875b351b60"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shared tasks\n",
    "Plusieurs tâches ont été proposées pour la correction grammaticale durant les années passées:\n",
    "- [CoNLL-2014](https://www.comp.nus.edu.sg/~nlp/conll14st.html) - ([*paper*](https://www.aclweb.org/anthology/W14-1701.pdf))\n",
    "- [BEA-2019](https://www.cl.cam.ac.uk/research/nl/bea2019st/) - ([*paper*](https://aclanthology.org/W19-4406.pdf))\n",
    "\n",
    "En se basant sur ces tâches, il nous est plus aisé de définir quels modèles choisirs et comment les évaluer. **Néanmoins** ces tâches datant de plusieurs années, et le monde de l'intelligence artificiel évoluant rapidement, les modèles utilisés ne sont plus les plus performants (SOTA). Nous allons donc nous baser sur les modèles les plus performants actuellement."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62884ca916f92979"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## State Of The Art\n",
    "Les modèles les plus performants ou les modèles d'état de l'art (State Of The Art) pour les tâches de GEC sont aujourd'hui principalement des modèles transformer [1;2;3;4]. Les modèles transformer sont des modèles de deep learning qui utilisent des mécanismes d'attention pour apprendre des représentations textuelles. Ces modèles sont très performants sur les tâches de NLP (Natural Language Processing) et sont donc très utilisés.\n",
    "\n",
    "Un modèle réputé pour être très performant est le modèle [T5](https://blog.research.google/2020/02/exploring-transfer-learning-with-t5.html) (Text-to-Text Transfer Transformer) de google. Ce modèle est un modèle transformer (encodeur - décodeur) qui a été pré-entrainé sur un très grand corpus de données. Il ne réalise pas directement la tâche de correction grammaticale mais il est capable de réaliser des tâches de text to text. C'est à dire qu'il prend en entrée un texte et renvoie un texte. Il est donc possible de l'utiliser pour la correction grammaticale, notamment en l'affinant sur un corpus de données de correction grammaticale.\n",
    "\n",
    "[*1- A Simple Recipe for Multilingual Grammatical Error Correction*](https://arxiv.org/pdf/2106.03830.pdf)\n",
    "[*2- Grammatical Error Correction: Are We There Yet?*](https://aclanthology.org/2022.coling-1.246/)\n",
    "[*3- A Comprehensive Survey of Grammatical Error Correction*](https://dl.acm.org/doi/abs/10.1145/3474840)\n",
    "[*4- Frustratingly Easy System Combination for Grammatical Error Correction*](https://aclanthology.org/2022.naacl-main.143/)\n",
    "[*5- BTS: Back TranScription for Speech-to-Text Post-Processor using Text-to-Speech-to-Text*](https://aclanthology.org/2021.wat-1.10.pdf)\n",
    "[*6- LM-Critic: Language Models for Unsupervised Grammatical Error Correction*](https://aclanthology.org/2021.emnlp-main.611.pdf)\n",
    "[*7- (Almost) Unsupervised Grammatical Error Correction using a Synthetic Comparable Corpus*](https://aclanthology.org/W19-4413.pdf)\n",
    "[*8- Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Method*](https://aclanthology.org/2023.bea-1.18.pdf)\n",
    "[*9- ChatGPT or Grammarly? Evaluating ChatGPT on Grammatical Error Correction Benchmark*](https://arxiv.org/abs/2303.13648)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e681150e5937a0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modèles\n",
    "\n",
    "Heureusement pour nous, des modèles pré-entrainés existent déjà et sont disponibles sur la librairie [huggingface](https://huggingface.co/). Ces modèles sont des modèles transformer qui ont été pré-entrainés sur des corpus de données de correction grammaticale.\n",
    "\n",
    "Modèles testés :\n",
    "- [T5](https://huggingface.co/vennify/t5-base-grammar-correction) (Text-to-Text Transfer Transformer)\n",
    "\n",
    "Autres modèles :\n",
    "- [BART](https://huggingface.co/facebook/bart-large-cnn) (Bidirectional and Auto-Regressive Transformers)\n",
    "- [GPT3](https://huggingface.co/transformers/model_doc/gpt_neo.html) (Generative Pre-trained Transformer 3)\n",
    "- [BERT](https://huggingface.co/transformers/model_doc/bert.html) (Bidirectional Encoder Representations from Transformers) - [GECwBERT](https://sunilchomal.github.io/GECwBERT/)\n",
    "\n",
    "Modèle utilisé en pipeline : [T5](https://huggingface.co/vennify/t5-base-grammar-correction)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7600c773045bf8b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "\n",
    "Plusieurs metrics existent pour évaluer des modèles GEC:\n",
    "- F0.5 \n",
    "- Exact match\n",
    "- [ERRANT](https://aclanthology.org/P17-1074.pdf)\n",
    "- [BERTScore](https://huggingface.co/spaces/evaluate-metric/bertscore)\n",
    "- BLEU\n",
    "- METEOR\n",
    "- ..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfbd9a659641c708"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Imports libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52d6dfdbe3f9505b"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: bert-score in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: transformers in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (4.36.2)\n",
      "Requirement already satisfied: datasets in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: happytransformer in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from bert-score) (2.1.1+cu121)\n",
      "Requirement already satisfied: pandas>=1.0.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from bert-score) (2.1.4)\n",
      "Requirement already satisfied: numpy in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from bert-score) (1.26.2)\n",
      "Requirement already satisfied: requests in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from bert-score) (4.66.1)\n",
      "Requirement already satisfied: matplotlib in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from bert-score) (3.8.2)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from bert-score) (23.2)\n",
      "Requirement already satisfied: filelock in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from datasets) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: xxhash in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from happytransformer) (0.1.99)\n",
      "Requirement already satisfied: protobuf in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from happytransformer) (4.23.4)\n",
      "Requirement already satisfied: accelerate<1.0.0,>=0.20.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from happytransformer) (0.25.0)\n",
      "Requirement already satisfied: wandb in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from happytransformer) (0.16.1)\n",
      "Requirement already satisfied: psutil in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (5.9.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from requests->bert-score) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from requests->bert-score) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from requests->bert-score) (2023.11.17)\n",
      "Requirement already satisfied: sympy in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Requirement already satisfied: colorama in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from matplotlib->bert-score) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from matplotlib->bert-score) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from matplotlib->bert-score) (3.1.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from wandb->happytransformer) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from wandb->happytransformer) (3.1.40)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from wandb->happytransformer) (1.38.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from wandb->happytransformer) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from wandb->happytransformer) (1.3.3)\n",
      "Requirement already satisfied: setuptools in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from wandb->happytransformer) (69.0.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from wandb->happytransformer) (1.4.4)\n",
      "Requirement already satisfied: six>=1.4.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb->happytransformer) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->happytransformer) (4.0.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\projets\\env\\3.10\\utils_env\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->happytransformer) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install bert-score transformers datasets happytransformer\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch, os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datetime import date\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "from happytransformer import HappyTextToText, TTSettings\n",
    "from evaluate import load\n",
    "\n",
    "bertscore = load(\"bertscore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:38:37.976711800Z",
     "start_time": "2023-12-22T00:38:33.169972800Z"
    }
   },
   "id": "a042e2fcde0a16c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Import des données\n",
    "\n",
    "Nous allons ici définir toutes les fonctions nécessaires à l'import des données. Nous avons besoin de deux datasets:\n",
    "- Un dataset pour les données en sortie de l'ASR\n",
    "- Un dataset pour les données de JFLEG (pour l'évaluation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb8a7173253b695a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class ASR_Dataset(Dataset):\n",
    "    def __init__(self, path, text=None):\n",
    "        \"\"\"\n",
    "        Dataset pour les données en sortie de l'ASR\n",
    "        :param path: Chemin des données\n",
    "        :param text: Texte à corriger (Default None, on utilise les données du path. Pour une utilisation du GEC en pipeline alors text est le texte à corriger)\n",
    "        \"\"\"\n",
    "        self.sentences = []\n",
    "        \n",
    "        if text is not None:\n",
    "            self.sentences.append(text.strip())\n",
    "        else:\n",
    "            self.path = path\n",
    "            self.files = os.listdir(path)\n",
    "            for file in self.files:\n",
    "                with open(path + '\\\\' + file, 'r', encoding='utf-8') as file:\n",
    "                    for line in file:\n",
    "                        self.sentences.append(line.strip())\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        transcript = self.sentences[idx]\n",
    "        return transcript\n",
    "\n",
    "\n",
    "def load_jfleg_dataset(path='data\\\\', text=None):\n",
    "    \"\"\"\n",
    "    Dataset pour les données de JFLEG\n",
    "    :param path: Chemin des données\n",
    "    :param text: Texte à corriger (Default None, on utilise les données du path. Pour une utilisation du GEC en pipeline alors text est le texte à corriger)\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    jfleg_dataset = load_dataset(\"jfleg\", \"test\", split=\"test[:10]\", cache_dir=path)\n",
    "    jfleg_Dataloader = DataLoader(jfleg_dataset, batch_size=1)\n",
    "    \n",
    "    print(\"Number of samples:\", len(jfleg_dataset))\n",
    "\n",
    "    sample_meta0 = jfleg_Dataloader.dataset[0]\n",
    "    print(\"\"\"\n",
    "    Transcript n°0 :\n",
    "\n",
    "    Path audio: {}\n",
    "    Sentence: {}\n",
    "    Corrections: {}\n",
    "    \"\"\".format(path, sample_meta0['sentence'], sample_meta0['corrections']))\n",
    "    \n",
    "    return jfleg_Dataloader\n",
    "\n",
    "\n",
    "def process_jfleg(data, model='T5'):\n",
    "    \"\"\"\n",
    "    Fonction de traitement des données JFLEG\n",
    "    :param data: Données à traiter\n",
    "    :param model: Modèle à utiliser\n",
    "    :return: Texte à corriger, checksum, corrections\n",
    "    \"\"\"\n",
    "    sentence = data['sentence']\n",
    "    corrections = data['corrections']\n",
    "    \n",
    "    return sentence[0], 0, corrections\n",
    "\n",
    "\n",
    "def load_ASR_dataset(path='data\\\\ASR', text=None, dataset=ASR_Dataset):\n",
    "    \"\"\"\n",
    "    Dataset pour les données en sortie de l'ASR\n",
    "    :param path: Chemin des données\n",
    "    :param text: Texte à corriger (Default None, on utilise les données du path. Pour une utilisation du GEC en pipeline alors text est le texte à corriger)\n",
    "    :param dataset: Classe du dataset à utiliser (Default ASR_Dataset)\n",
    "    :return: Dataloader ASR\n",
    "    \"\"\"\n",
    "    ASR_Dataset = dataset(path, text)\n",
    "    ASR_Dataloader = DataLoader(ASR_Dataset, batch_size=1)\n",
    "    \n",
    "    print(\"Number of samples:\", len(ASR_Dataset))\n",
    "    \n",
    "    sample_meta0 = ASR_Dataset\n",
    "    print(\"\"\"\n",
    "    Transcript n°0 :\n",
    "    \n",
    "    Transcript : {}\n",
    "    \"\"\".format(*sample_meta0))\n",
    "    \n",
    "    return ASR_Dataloader\n",
    "\n",
    "def process_ASR(data, model='T5'):\n",
    "    \"\"\"\n",
    "    Fonction de traitement des données ASR\n",
    "    :param data: Données à traiter\n",
    "    :param model: Modèle à utiliser\n",
    "    :return: Texte à corriger, checksum, None\n",
    "    \"\"\"\n",
    "    return data[0], 0, None\n",
    "\n",
    "\n",
    "def evaluate_jfleg(input, labels, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Fonction d'évaluation des corrections avec JFLEG\n",
    "    :param input: Texte à corriger\n",
    "    :param labels: Liste des corrections\n",
    "    :param model: Modèle à utiliser\n",
    "    :param tokenizer: Tokenizer à utiliser\n",
    "    :return: Meilleure correction, score de la correction, score BERT\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    bert_scores = []\n",
    "    for correction in labels:\n",
    "        # Vérifie si la correction est exacte, si oui alors pas besoin de passer par le modèle\n",
    "        if load('exact_match').compute(references=correction, predictions=[input])['exact_match'] == 1:\n",
    "            return correction, 5, None\n",
    "        \n",
    "        # Calcul du score BERT\n",
    "        bert_scores.append(bertscore.compute(predictions=[input], references=correction, lang=\"en\"))\n",
    "        \n",
    "        # Calcul du score T5\n",
    "        input_ids = tokenizer.encode(\"stsb sentence 1: \"+input+\" sentence 2: \"+correction[0], return_tensors=\"pt\").to(\"cuda\")\n",
    "        stsb_ids = model.generate(input_ids)\n",
    "        stsb = tokenizer.decode(stsb_ids[0],skip_special_tokens=True)\n",
    "        results.append(float(stsb))\n",
    "    \n",
    "    # Récupération de la meilleure correction\n",
    "    max_arg = results.index(max(results))\n",
    "    max_score = results[max_arg]\n",
    "    \n",
    "    # Récupération du meilleur score BERT\n",
    "    max_bert = {}\n",
    "    for scores in bert_scores:\n",
    "        for key, value in scores.items():\n",
    "            if key != \"hashcode\":\n",
    "                if key not in max_bert:\n",
    "                    max_bert[key] = value\n",
    "                else:\n",
    "                    max_bert[key] = max(max_bert[key], value)\n",
    "    \n",
    "    return labels[max_arg], max_score, max_bert\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:38:38.018623700Z",
     "start_time": "2023-12-22T00:38:37.977855900Z"
    }
   },
   "id": "5edb74092353347e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Fonction de correction grammaticale\n",
    "\n",
    "Nous allons ici définir la fonction de correction grammaticale. Cette fonction prend en entrée un texte et renvoie un texte corrigé.\n",
    "En mode test, cette fonction prend en entrée un chemin de dataset et renvoie un fichier de corrections."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6625355f301b6b0"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def GEC(text:str = None, model='T5', output_folder='output', dataset='ASR'):\n",
    "    \"\"\"\n",
    "    Fonction de correction grammaticale\n",
    "    :param text: Texte à corriger (Default None, on utilise les données du chemin du dataset. Pour une utilisation du GEC en pipeline alors text est le texte à corriger)\n",
    "    :param model: Modèle à utiliser (Default T5)\n",
    "    :param output_folder: Dossier de sortie (Default output)\n",
    "    :param dataset: Dataset à utiliser (Default ASR)\n",
    "    :return: Texte corrigé\n",
    "    \"\"\"\n",
    "\n",
    "    # Création des chemins de sortie\n",
    "    pipeline = \"/pipeline/\" if text is not None else \"/\"\n",
    "    correction_folder = output_folder + pipeline + model + '_' + dataset\n",
    "    \n",
    "    # Chemins de sortie pour les évaluations\n",
    "    correction_file =f'{correction_folder}/output_GEC.{date.today()}.txt'\n",
    "    verification = f'{correction_folder}/Verification.{date.today()}.txt'\n",
    "    vard = f'{correction_folder}/vard.{date.today()}.txt'\n",
    "    \n",
    "    os.makedirs(correction_folder, exist_ok=True)\n",
    "    \n",
    "    #TQDM loader et fonction de traitement des données\n",
    "    try:\n",
    "        function = \"load_\" + dataset + \"_dataset\"\n",
    "        dataloader = eval(function)(text=text)\n",
    "        dataloader_tqdm = tqdm(dataloader, total=len(dataloader))\n",
    "        \n",
    "        process_function = \"process_\" + dataset\n",
    "    except Exception as e:\n",
    "        raise ValueError(f'Unknown dataset {dataset}{e}')\n",
    "    \n",
    "    # Création du modèle\n",
    "    print(f'Generating corrections for {dataset} with {model} in {correction_folder}')\n",
    "    \n",
    "    if model == 'T5':\n",
    "        T5 = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\n",
    "        args = TTSettings(num_beams=5, min_length=1, max_length=100)\n",
    "    \n",
    "    with open(correction_file, 'w', encoding='utf-8') as file:\n",
    "        file.write('')\n",
    "    \n",
    "    # Création des fichiers de vérification et de vard pour JFLEG (pour l'évaluation)\n",
    "    result = \"\"\n",
    "    if dataset == 'jfleg':\n",
    "        with open(verification, 'w', encoding='utf-8') as file:\n",
    "                    file.write('')\n",
    "        with open(vard, 'w', encoding='utf-8') as file:\n",
    "                    file.write('')\n",
    "        # Création du modèle pour l'évaluation\n",
    "        tokenizer = T5Tokenizer.from_pretrained('t5-base', model_max_length=512)\n",
    "        model_evaluation = T5ForConditionalGeneration.from_pretrained('t5-base').to(\"cuda\")\n",
    "        mean_evaluation_score = 0\n",
    "        mean_bert = {}\n",
    "    \n",
    "    # Boucle de traitement des données \n",
    "    for i, data in enumerate(dataloader_tqdm):\n",
    "        # Récupération du texte à corriger\n",
    "        (sentence, out, extra) = eval(process_function)(data, model=model)\n",
    "        \n",
    "        # Vérification du checksum\n",
    "        if out == 1:\n",
    "            dataloader_tqdm.set_postfix({'status': 'Skipped', 'ID': i})\n",
    "            continue\n",
    "            \n",
    "        # Correction du texte\n",
    "        try:\n",
    "            #Passage du transcript dans le modèle\n",
    "            if model == 'T5':\n",
    "                result = T5.generate_text(\"grammar:\" + sentence, args=args).text\n",
    "                with open(correction_file, 'a', encoding='utf-8') as file:\n",
    "                    file.write(result + '\\n')\n",
    "                if dataset == 'jfleg':\n",
    "                    with open(vard, 'a', encoding='utf-8') as file:\n",
    "                        file.write(sentence + '\\n')\n",
    "            elif model == 'BART':\n",
    "                result = ''\n",
    "            else:\n",
    "                raise ValueError(f'Unknown model {model}')\n",
    "            \n",
    "            dataloader_tqdm.set_postfix()\n",
    "\n",
    "        except Exception as e:\n",
    "            dataloader_tqdm.set_postfix({'status': 'Error', 'ID': i})\n",
    "            raise e \n",
    "        \n",
    "        # Evaluation du modèle\n",
    "        if extra is not None:\n",
    "            best_correction, t5sim, bert_score = evaluate_jfleg(sentence, extra, model_evaluation, tokenizer)\n",
    "            mean_evaluation_score += t5sim\n",
    "            \n",
    "            with open(verification, 'a', encoding='utf-8') as file:\n",
    "                file.write(best_correction[0] + '\\n')\n",
    "            \n",
    "            if bert_score is not None:\n",
    "                for key, value in bert_score.items():\n",
    "                    val = value[0]\n",
    "                    if key not in mean_bert:\n",
    "                        mean_bert[key] = val\n",
    "                    else:\n",
    "                        mean_bert[key] += val\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # Affichage des résultats\n",
    "    if extra is not None:\n",
    "        result = f'Mean evaluation score T5: {mean_evaluation_score/len(dataloader)}\\n'\n",
    "        for key, value in mean_bert.items():\n",
    "            mean_bert[key] /= len(dataloader)\n",
    "            result += f'Mean {key} score: {mean_bert[key]}\\n'\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:38:38.037833200Z",
     "start_time": "2023-12-22T00:38:38.015551800Z"
    }
   },
   "id": "45b5c48f45f4e44b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Tests des modèles et des datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a31052a17418fb8a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# # # T5 avec dataset ASR de pipeline\n",
    "# correction = GEC(\"I don't have a car but I dreaming it off\")\n",
    "# print(correction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:38:38.070675900Z",
     "start_time": "2023-12-22T00:38:38.039402300Z"
    }
   },
   "id": "d2096e10d61676a4"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# # T5 avec dataset ASR\n",
    "# GEC(model='T5', output_folder='output', dataset='ASR')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:38:38.071674900Z",
     "start_time": "2023-12-22T00:38:38.055480500Z"
    }
   },
   "id": "f53a6e0cb62d5ebc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10\n",
      "\n",
      "    Transcript n°0 :\n",
      "\n",
      "    Path audio: data\\\n",
      "    Sentence: New and new technology has been introduced to the society .\n",
      "    Corrections: ['New technology has been introduced to society .', 'New technology has been introduced into the society .', 'Newer and newer technology has been introduced into society .', 'Newer and newer technology has been introduced to the society .']\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f05b4c042669491b9d62b76bd5ee99c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating corrections for jfleg with T5 in output/T5_jfleg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/21/2023 19:38:40 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "12/21/2023 19:38:47 - INFO - happytransformer.happy_transformer -   Moving model to cuda:0\n",
      "12/21/2023 19:38:48 - INFO - happytransformer.happy_transformer -   Initializing a pipeline\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Mean evaluation score T5: 4.86\\nMean precision score: 0.7689380943775177\\nMean recall score: 0.7803486764431\\nMean f1 score: 0.7745508134365082\\n'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # T5 avec dataset JFLEG\n",
    "# GEC(model='T5', output_folder='output', dataset='jfleg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:40:06.004993300Z",
     "start_time": "2023-12-22T00:38:38.072674700Z"
    }
   },
   "id": "514330ac0fc15077"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Autres tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63092227cb1eca35"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# model_b = T5ForConditionalGeneration.from_pretrained('t5-small').to(\"cuda\")\n",
    "# stsb_sentence_1 = preprocess_text\n",
    "# stsb_sentence_2 = output\n",
    "# input_ids = tokenizer.encode(\"stsb sentence 1: \"+stsb_sentence_1+\" sentence 2: \"+stsb_sentence_2, return_tensors=\"pt\").to(\"cuda\")\n",
    "# stsb_ids = model_b.generate(input_ids)\n",
    "# stsb = tokenizer.decode(stsb_ids[0],skip_special_tokens=True)\n",
    "# print(stsb)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:40:06.047761800Z",
     "start_time": "2023-12-22T00:40:06.009647200Z"
    }
   },
   "id": "c05518eae2bd36be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
