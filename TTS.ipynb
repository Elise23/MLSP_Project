{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## TTS module for our Pipeline\n",
    "\n",
    "Dans ce notebook on va générer des fichiers audios à partir de textes.\n",
    "\n",
    "On va premièrement utiliser le modèle [gTTS](https://gtts.readthedocs.io/en/latest/) qui est un modèle de TTS (Text To Speech) basé sur Google Translate.\n",
    "Sur ce modèle nous allons utiliser le dataset [LibriSpeech](https://huggingface.co/datasets/librispeech_asr) qui est un dataset de textes en anglais. Celui ci nous permettra d'évaluer la qualité de notre modèle.\n",
    "\n",
    "Ensuite, nous utilisons le dataset des transcripts de sortie du GEC. Cette partie simulera l'utilisation de notre modèle dans la pipeline, et pourra être réutilisée directement dans la pipeline si les résultats sont considérés comme satisfaisants.\n",
    "\n",
    "\n",
    "Autres modèles de TTS :\n",
    "- [Tacotron2](https://huggingface.co/transformers/model_doc/tacotron2.html) (exemple avec vocodeur HiFiGAN, sur modèle pré-entrainé avec le dataset LJSpeech [ici](https://huggingface.co/speechbrain/tts-tacotron2-ljspeech))\n",
    "- [FastSpeech2](https://fastspeech2.github.io/fastspeech2/)\n",
    "Vocodeurs:\n",
    "- [HiFiGAN](https://pytorch.org/hub/nvidia_deeplearningexamples_hifigan/)\n",
    "- [MelGAN](https://paperswithcode.com/method/melgan)\n",
    "\n",
    "\n",
    "Les datasets se trouvent dans un dossier `data/` et les fichiers audios générés dans un dossier `output/`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9e6e100228ae717"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import des librairies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f008b45fc82f23"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torchaudio, torch, os\n",
    "import IPython.display as ipd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from gtts import gTTS\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:16:23.350777Z",
     "start_time": "2023-12-03T22:16:23.307342800Z"
    }
   },
   "id": "30ea638c53648590"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Définition des fonctions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e40f713ac9c22e9b"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class GEC_Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.files = os.listdir(path)\n",
    "        self.sentences = []\n",
    "        for file in self.files:\n",
    "            with open(path + '\\\\' + file, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    self.sentences.append(line.strip())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        transcript = self.sentences[idx]\n",
    "\n",
    "        return transcript, idx\n",
    "\n",
    "\n",
    "def load_librispeech_dataset(path='data\\\\'):\n",
    "    librispeech_dataset = torchaudio.datasets.LIBRISPEECH(path, url='dev-clean', download=True)\n",
    "    #Shorten dataset to 500 samples\n",
    "    librispeech_dataset_short = torch.utils.data.Subset(librispeech_dataset, range(500))\n",
    "    librispeech_dataloader = DataLoader(librispeech_dataset_short, batch_size=1)\n",
    "    \n",
    "    print(\"Number of samples:\", len(librispeech_dataset_short))\n",
    "    \n",
    "    sample_meta0 = librispeech_dataset.get_metadata(0)\n",
    "    sample_0 = librispeech_dataset_short[0][0]\n",
    "    print(\"\"\"\n",
    "    Audio n°0 :\n",
    "    \n",
    "    Path audio: {}{}\n",
    "    Sample rate : {}\n",
    "    Transcript : {}\n",
    "    Speaker ID : {}\n",
    "    Chapter ID : {}\n",
    "    Utterance ID : {}\n",
    "    \"\"\".format(path + \"LibriSpeech\", *sample_meta0))\n",
    "    \n",
    "    #Playing sample_O\n",
    "    ipd.Audio(sample_0, rate=sample_meta0[1])\n",
    "    \n",
    "    return librispeech_dataloader\n",
    "\n",
    "def process_librispeech(data, model='gtts', output_folder='output'):\n",
    "    (waveform, sample_rate, transcript, ID_s, ID_c, ID_u) = data\n",
    "    \n",
    "    waveform = waveform.squeeze(0)\n",
    "    sample_rate = sample_rate.squeeze(0)\n",
    "    transcript = str(transcript[0])\n",
    "    ID = \"-\".join((str(ID_s.item()), str(ID_c.item()), str(ID_u.item()))).replace(',','')\n",
    "    \n",
    "    file = f'./{output_folder}/out_{ID}.mp3'\n",
    "    \n",
    "    if os.path.exists(file):\n",
    "        return ID, file, 1, _\n",
    "    \n",
    "    return ID, file, 0, transcript\n",
    "\n",
    "\n",
    "def load_GEC_dataset(path='data\\\\GEC', dataset=GEC_Dataset):\n",
    "    GEC_Dataset = dataset(path)\n",
    "    GEC_Dataloader = DataLoader(GEC_Dataset, batch_size=1)\n",
    "    \n",
    "    print(\"Number of samples:\", len(GEC_Dataset))\n",
    "    \n",
    "    sample_meta0 = GEC_Dataloader.dataset[0]\n",
    "    print(\"\"\"\n",
    "    Transcript n°0 :\n",
    "    \n",
    "    Transcript : {}\n",
    "    Transcript ID : {}\n",
    "    \"\"\".format(*sample_meta0))\n",
    "    \n",
    "    return GEC_Dataloader\n",
    "\n",
    "\n",
    "def process_GEC(data, model='gtts', output_folder='output'):\n",
    "    (transcript, ID) = data\n",
    "    ID = ID.item()\n",
    "    file = f'./{output_folder}/out_{ID}.mp3'\n",
    "    \n",
    "    if os.path.exists(file):\n",
    "        return ID, file, 1, _\n",
    "    \n",
    "    return ID, file, 0, transcript"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:18:00.913391Z",
     "start_time": "2023-12-03T22:18:00.902456400Z"
    }
   },
   "id": "6f03872312cff1f6"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def TTS(model='gtts', output_folder='output', dataset='librispeech'):\n",
    "    output_folder = output_folder + '/' + model + '_' + dataset\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    # TQDM loader\n",
    "    try:\n",
    "        function = \"load_\" + dataset + \"_dataset\"\n",
    "        dataloader = eval(function)()\n",
    "        dataloader_tqdm = tqdm(dataloader, total=len(dataloader))\n",
    "    \n",
    "        process_function = \"process_\" + dataset\n",
    "        \n",
    "    except NameError:\n",
    "        raise ValueError(f'Unknown dataset {dataset}')\n",
    "    \n",
    "    print(f'Generating audio files with {model} model in {output_folder} folder')\n",
    "    \n",
    "    for i, data in enumerate(dataloader_tqdm):\n",
    "        (ID, file_out, out, transcript) = eval(process_function)(data, model=model, output_folder=output_folder)\n",
    "        file_out = file_out if type(file_out) == str else file_out[0]\n",
    "        transcript = str(transcript)\n",
    "        if out == 1:\n",
    "            dataloader_tqdm.set_postfix({'status': 'Skipped', 'ID': ID})\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            #Passage du transcript dans le modèle\n",
    "            if model == 'gtts':\n",
    "                tts = gTTS(transcript, lang='en', tld='co.in')\n",
    "                tts.save(file_out)\n",
    "            elif model == 'tacotron2':\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(f'Unknown model {model}')\n",
    "            \n",
    "            dataloader_tqdm.set_postfix()\n",
    "\n",
    "        except Exception as e:\n",
    "            dataloader_tqdm.set_postfix({'status': 'Error', 'ID': ID})\n",
    "            raise e\n",
    "            \n",
    "        \n",
    "        #Vérification\n",
    "        # Comparer les fichiers audios générés avec les fichiers audios du dataset (spectrogrammes ?)\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:18:01.137699100Z",
     "start_time": "2023-12-03T22:18:01.123635300Z"
    }
   },
   "id": "ad05bc0ee24afe69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## TTS model gtts\n",
    "### Dataset Librispeech\n",
    "Le même qu'on a utilisé pour générer les fichiers audios pour le dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6336b7c6ec1a2f7"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 500\n",
      "\n",
      "    Audio n°0 :\n",
      "    \n",
      "    Path audio: data\\LibriSpeechdev-clean\\1272\\128104\\1272-128104-0000.flac\n",
      "    Sample rate : 16000\n",
      "    Transcript : MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL\n",
      "    Speaker ID : 1272\n",
      "    Chapter ID : 128104\n",
      "    Utterance ID : 0\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccdb310101ba4a70850b9ead68f4a88d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio files with gtts model in output/gtts_librispeech folder\n"
     ]
    }
   ],
   "source": [
    "TTS(model='gtts', output_folder='output', dataset='librispeech')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:16:54.188630200Z",
     "start_time": "2023-12-03T22:16:51.319620500Z"
    }
   },
   "id": "16610c327e11f0a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dataset GEC (pour pipeline)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ba41aae40edd68a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 17\n",
      "\n",
      "    Transcript n°0 :\n",
      "    \n",
      "    Transcript : She doesn't like to eat vegetables.\n",
      "    Transcript ID : 0\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/17 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68e4b086ae79447cb3f7086a6b0da7bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio files with gtts model in output/gtts_GEC folder\n"
     ]
    }
   ],
   "source": [
    "TTS(model=\"gtts\", output_folder=\"output\", dataset=\"GEC\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:18:12.936185800Z",
     "start_time": "2023-12-03T22:18:05.889594700Z"
    }
   },
   "id": "7b4eb5a265d99e4c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
