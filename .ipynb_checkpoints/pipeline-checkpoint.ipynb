{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline\n",
    "\n",
    "Dans ce notebook nous allons définir notre pipeline de correction automatique de texte. Il sera composé de 3 étapes :\n",
    "- Reconnaissance vocale\n",
    "- Correction du texte\n",
    "- Synthèse vocale\n",
    "\n",
    "En se basant sur les notebook créé pour chacun des modèles, nous allons créer un pipeline qui prendra en entrée un fichier audio et qui retournera un fichier audio avec le texte corrigé."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4316efd6281b808e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import des dépendances"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61f5ed4d87b29350"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from GEC.ipynb\n",
      "importing Jupyter notebook from TTS.ipynb\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q import_ipynb\n",
    "import import_ipynb, os, pyaudio, wave\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from transformers import pipeline\n",
    "\n",
    "# Import des notebooks\n",
    "from GEC import GEC\n",
    "from TTS import TTS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-19T19:22:43.527765800Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Définition des paramètres\n",
    "\n",
    "Préparation de l'interface pour récupérer le fichier audio, et récupération du modèle ASR sur HuggingFace."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de1cf293e3c9a011"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "ASR = pipeline(\"automatic-speech-recognition\", model=\"EliseB/whisper-base-dv\")\n",
    "\n",
    "# Gestion de la fenêtre de dialogue\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "\n",
    "speech_file = askopenfilename(initialdir=\"C:/Users/virtu/Documents/Enregistrements audio\")\n",
    "display(ipd.Audio(filename=speech_file))\n",
    "root.destroy()\n",
    "\n",
    "%gui tk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T19:22:58.393767500Z",
     "start_time": "2023-12-19T19:22:57.201658Z"
    }
   },
   "id": "83f32931f4b887e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reconnaissance vocale\n",
    "\n",
    "Appel de notre modèle pré-entrainé pour la reconnaissance vocale, avec Whisper."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e9abad67affde53"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Appel du module ASR\n",
    "text = ASR(speech_file)['text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T19:23:07.171366600Z",
     "start_time": "2023-12-19T19:22:58.398775100Z"
    }
   },
   "id": "13d5e1aa15d83fd2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correction du texte\n",
    "\n",
    "Appel de notre modèle pré-entrainé pour la correction du texte, avec T5."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84b8215eacbed060"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1\n",
      "\n",
      "    Transcript n°0 :\n",
      "    \n",
      "    Transcript : Last weekend me and my family goes on a road trip to the mountains but the car breaks down in a middle of nowhere and no one knows how to fixing it.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d5ecd2c8d0f4b0eb525753545a29163"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating corrections for ASR with T5 in output/pipeline/T5_ASR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/19/2023 14:23:09 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "12/19/2023 14:23:11 - INFO - happytransformer.happy_transformer -   Moving model to cuda:0\n",
      "12/19/2023 14:23:11 - INFO - happytransformer.happy_transformer -   Initializing a pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last weekend, me and my family went on a road trip to the mountains, but the car broke down in a middle of nowhere and no one knows how to fix it.\n"
     ]
    }
   ],
   "source": [
    "corrected_text = GEC(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T19:23:13.136725100Z",
     "start_time": "2023-12-19T19:23:07.253388600Z"
    }
   },
   "id": "7cf666803458bc91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Synthèse vocale\n",
    "\n",
    "Appel de notre modèle pré-entrainé pour la synthèse vocale, avec gTTS."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f8f76d2978df01f"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "audio, rate = TTS(corrected_text)\n",
    "ipd.Audio(audio, rate=rate)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1257f06d0725404"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
