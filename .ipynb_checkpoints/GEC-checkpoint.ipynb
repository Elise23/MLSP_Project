{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <center> GRAMMATICAL ERROR CORRECTION\n",
    "\n",
    "Notebook de test et d'implémentation de modèles de GEC.\n",
    "Pour notre GEC nous avons besoin d'un modèle qui prend en entrée un texte et qui renvoie un texte corrigé. Ce genre de modèles s'apparentent à des modèles seq2seq."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "197498875b351b60"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shared tasks\n",
    "Plusieurs tâches ont été proposées pour la correction grammaticale durant les années passées:\n",
    "- [CoNLL-2014](https://www.comp.nus.edu.sg/~nlp/conll14st.html) - ([*paper*](https://www.aclweb.org/anthology/W14-1701.pdf))\n",
    "- [BEA-2019](https://www.cl.cam.ac.uk/research/nl/bea2019st/) - ([*paper*](https://www.aclweb.org/anthology/W19-4413.pdf))\n",
    "\n",
    "En se basant sur ces tâches, il nous est plus aisé de définir quels modèles choirs et comment les évaluer. **Néanmoins** ces tâches datant de plusieurs années, et le monde de l'intelligence artificiel évoluant rapidement, les modèles utilisés ne sont plus les plus performants (SOTA). Nous allons donc nous baser sur les modèles les plus performants actuellement."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62884ca916f92979"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## State Of The Art\n",
    "Les modèles les plus performants ou les modèles d'état de l'art (State Of The Art) pour les tâches de GEC sont aujourd'hui principalement des modèles transformer [1;2;3;4]. Les modèles transformer sont des modèles de deep learning qui utilisent des mécanismes d'attention pour apprendre des représentations textuelles. Ces modèles sont très performants sur les tâches de NLP (Natural Language Processing) et sont donc très utilisés.\n",
    "\n",
    "Un modèle réputé pour être très performant est le modèle [T5](https://blog.research.google/2020/02/exploring-transfer-learning-with-t5.html) (Text-to-Text Transfer Transformer) de google. Ce modèle est un modèle transformer (encodeur - décodeur) qui a été pré-entrainé sur un très grand corpus de données. Il ne réalise pas directement la tâche de correction grammaticale mais il est capable de réaliser des tâches de text to text. C'est à dire qu'il prend en entrée un texte et renvoie un texte. Il est donc possible de l'utiliser pour la correction grammaticale, notamment en l'affinant sur un corpus de données de correction grammaticale.\n",
    "\n",
    "[*1- A Simple Recipe for Multilingual Grammatical Error Correction*](https://arxiv.org/pdf/2106.03830.pdf)\n",
    "[*2- Grammatical Error Correction: Are We There Yet?*](https://aclanthology.org/2022.coling-1.246/)\n",
    "[*3- A Comprehensive Survey of Grammatical Error Correction*](https://dl.acm.org/doi/abs/10.1145/3474840)\n",
    "[*4- Frustratingly Easy System Combination for Grammatical Error Correction*](https://aclanthology.org/2022.naacl-main.143/)\n",
    "[*5- BTS: Back TranScription for Speech-to-Text Post-Processor using Text-to-Speech-to-Text*](https://aclanthology.org/2021.wat-1.10.pdf)\n",
    "[*6- LM-Critic: Language Models for Unsupervised Grammatical Error Correction*](https://aclanthology.org/2021.emnlp-main.611.pdf)\n",
    "[*7- (Almost) Unsupervised Grammatical Error Correction using a Synthetic Comparable Corpus*](https://aclanthology.org/W19-4413.pdf)\n",
    "[*8- Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Method*](https://aclanthology.org/2023.bea-1.18.pdf)\n",
    "[*9- ChatGPT or Grammarly? Evaluating ChatGPT on Grammatical Error Correction Benchmark*](https://arxiv.org/abs/2303.13648)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e681150e5937a0d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "68c7b0a36e5ca42c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modèles\n",
    "\n",
    "Heureusement pour nous, des modèles pré-entrainés existent déjà et sont disponibles sur la librairie [huggingface](https://huggingface.co/). Ces modèles sont des modèles transformer qui ont été pré-entrainés sur des corpus de données de correction grammaticale.\n",
    "\n",
    "Modèles testés :\n",
    "- [T5](https://huggingface.co/vennify/t5-base-grammar-correction) (Text-to-Text Transfer Transformer)\n",
    "\n",
    "Autres modèles :\n",
    "- [BART](https://huggingface.co/facebook/bart-large-cnn) (Bidirectional and Auto-Regressive Transformers)\n",
    "- [GPT3](https://huggingface.co/transformers/model_doc/gpt_neo.html) (Generative Pre-trained Transformer 3)\n",
    "- [BERT](https://huggingface.co/transformers/model_doc/bert.html) (Bidirectional Encoder Representations from Transformers) - [GECwBERT](https://sunilchomal.github.io/GECwBERT/)\n",
    "\n",
    "Modèle utilisé en pipeline : [T5](https://huggingface.co/vennify/t5-base-grammar-correction)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7600c773045bf8b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "\n",
    "Plusieurs metrics existent pour évaluer des modèles GEC:\n",
    "- F0.5 \n",
    "- Exact match\n",
    "- [ERRANT](https://aclanthology.org/P17-1074.pdf)\n",
    "- [BERTScore](https://huggingface.co/spaces/evaluate-metric/bertscore)\n",
    "- BLEU\n",
    "- METEOR\n",
    "- ..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfbd9a659641c708"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Imports libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52d6dfdbe3f9505b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch, os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datetime import date\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "from happytransformer import HappyTextToText, TTSettings\n",
    "from evaluate import load\n",
    "\n",
    "#!pip3 install bert-score\n",
    "bertscore = load(\"bertscore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:13:52.900139500Z",
     "start_time": "2023-12-12T03:13:39.530331Z"
    }
   },
   "id": "a042e2fcde0a16c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Import des données"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb8a7173253b695a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class ASR_Dataset(Dataset):\n",
    "    def __init__(self, path, text=None):\n",
    "        \"\"\"\n",
    "        Dataset pour les données en sortie de l'ASR\n",
    "        :param path: Chemin des données\n",
    "        :param text: Texte à corriger (Default None, on utilise les données du path. Pour une utilisation du GEC en pipeline alors text est le texte à corriger)\n",
    "        \"\"\"\n",
    "        self.sentences = []\n",
    "        \n",
    "        if text is not None:\n",
    "            self.sentences.append(text.strip())\n",
    "        else:\n",
    "            self.path = path\n",
    "            self.files = os.listdir(path)\n",
    "            for file in self.files:\n",
    "                with open(path + '\\\\' + file, 'r', encoding='utf-8') as file:\n",
    "                    for line in file:\n",
    "                        self.sentences.append(line.strip())\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        transcript = self.sentences[idx]\n",
    "        return transcript\n",
    "\n",
    "\n",
    "def load_jfleg_dataset(path='data\\\\', text=None):\n",
    "    \"\"\"\n",
    "    Dataset pour les données de JFLEG\n",
    "    :param path: Chemin des données\n",
    "    :param text: Texte à corriger (Default None, on utilise les données du path. Pour une utilisation du GEC en pipeline alors text est le texte à corriger)\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    jfleg_dataset = load_dataset(\"jfleg\", \"test\", split=\"test\", cache_dir=path)\n",
    "    jfleg_Dataloader = DataLoader(jfleg_dataset, batch_size=1)\n",
    "    \n",
    "    print(\"Number of samples:\", len(jfleg_dataset))\n",
    "\n",
    "    sample_meta0 = jfleg_Dataloader.dataset[0]\n",
    "    print(\"\"\"\n",
    "    Transcript n°0 :\n",
    "\n",
    "    Path audio: {}\n",
    "    Sentence: {}\n",
    "    Corrections: {}\n",
    "    \"\"\".format(path, sample_meta0['sentence'], sample_meta0['corrections']))\n",
    "    \n",
    "    return jfleg_Dataloader\n",
    "\n",
    "\n",
    "def process_jfleg(data, model='T5'):\n",
    "    sentence = data['sentence']\n",
    "    corrections = data['corrections']\n",
    "    \n",
    "    return sentence[0], 0, corrections\n",
    "\n",
    "\n",
    "def load_ASR_dataset(path='data\\\\ASR', text=None, dataset=ASR_Dataset):\n",
    "    \"\"\"\n",
    "    Dataset pour les données en sortie de l'ASR\n",
    "    :param path: Chemin des données\n",
    "    :param text: Texte à corriger (Default None, on utilise les données du path. Pour une utilisation du GEC en pipeline alors text est le texte à corriger)\n",
    "    :param dataset: Classe du dataset à utiliser (Default ASR_Dataset)\n",
    "    :return: Dataloader ASR\n",
    "    \"\"\"\n",
    "    ASR_Dataset = dataset(path, text)\n",
    "    ASR_Dataloader = DataLoader(ASR_Dataset, batch_size=1)\n",
    "    \n",
    "    print(\"Number of samples:\", len(ASR_Dataset))\n",
    "    \n",
    "    sample_meta0 = ASR_Dataset\n",
    "    print(\"\"\"\n",
    "    Transcript n°0 :\n",
    "    \n",
    "    Transcript : {}\n",
    "    \"\"\".format(*sample_meta0))\n",
    "    \n",
    "    return ASR_Dataloader\n",
    "\n",
    "def process_ASR(data, model='T5'):\n",
    "    return data[0], 0, None\n",
    "\n",
    "\n",
    "def evaluate_jfleg(input, labels, model, tokenizer):\n",
    "    results = []\n",
    "    bert_scores = []\n",
    "    for correction in labels:\n",
    "        if load('exact_match').compute(references=correction, predictions=[input])['exact_match'] == 1:\n",
    "            return correction, 5, None\n",
    "        \n",
    "        bert_scores.append(bertscore.compute(predictions=[input], references=correction, lang=\"en\"))\n",
    "        input_ids = tokenizer.encode(\"stsb sentence 1: \"+input+\" sentence 2: \"+correction[0], return_tensors=\"pt\").to(\"cuda\")\n",
    "        stsb_ids = model.generate(input_ids)\n",
    "        stsb = tokenizer.decode(stsb_ids[0],skip_special_tokens=True)\n",
    "        results.append(float(stsb))\n",
    "    \n",
    "    max_arg = results.index(max(results))\n",
    "    max_score = results[max_arg]\n",
    "    \n",
    "    max_bert = {}\n",
    "    for scores in bert_scores:\n",
    "        for key, value in scores.items():\n",
    "            if key != \"hashcode\":\n",
    "                if key not in max_bert:\n",
    "                    max_bert[key] = value\n",
    "                else:\n",
    "                    max_bert[key] = max(max_bert[key], value)\n",
    "    \n",
    "    return labels[max_arg], max_score, max_bert\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T04:58:53.094756500Z",
     "start_time": "2023-12-12T04:58:53.059067200Z"
    }
   },
   "id": "5edb74092353347e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def GEC(text:str = None, model='T5', output_folder='output', dataset='ASR'):\n",
    "    \"\"\"\n",
    "    Fonction de correction grammaticale\n",
    "    :param text: Texte à corriger (Default None, on utilise les données du chemin du dataset. Pour une utilisation du GEC en pipeline alors text est le texte à corriger)\n",
    "    :param model: Modèle à utiliser (Default T5)\n",
    "    :param output_folder: Dossier de sortie (Default output)\n",
    "    :param dataset: Dataset à utiliser (Default ASR)\n",
    "    :return: Texte corrigé\n",
    "    \"\"\"\n",
    "\n",
    "    pipeline = \"/pipeline/\" if text is not None else \"/\"\n",
    "    correction_folder = output_folder + pipeline + model + '_' + dataset\n",
    "    \n",
    "    correction_file =f'{correction_folder}/output_GEC.{date.today()}.txt'\n",
    "    verification = f'{correction_folder}/Verification.{date.today()}.txt'\n",
    "    vard = f'{correction_folder}/vard.{date.today()}.txt'\n",
    "    \n",
    "    os.makedirs(correction_folder, exist_ok=True)\n",
    "    \n",
    "    #TQDM loader\n",
    "    try:\n",
    "        function = \"load_\" + dataset + \"_dataset\"\n",
    "        dataloader = eval(function)(text=text)\n",
    "        dataloader_tqdm = tqdm(dataloader, total=len(dataloader))\n",
    "        \n",
    "        process_function = \"process_\" + dataset\n",
    "    except Exception as e:\n",
    "        raise ValueError(f'Unknown dataset {dataset}{e}')\n",
    "    \n",
    "    print(f'Generating corrections for {dataset} with {model} in {correction_folder}')\n",
    "    if model == 'T5':\n",
    "        T5 = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\n",
    "        args = TTSettings(num_beams=5, min_length=1, max_length=100)\n",
    "    \n",
    "    with open(correction_file, 'w', encoding='utf-8') as file:\n",
    "        file.write('')\n",
    "        \n",
    "    if dataset == 'jfleg':\n",
    "        with open(verification, 'w', encoding='utf-8') as file:\n",
    "                    file.write('')\n",
    "        with open(vard, 'w', encoding='utf-8') as file:\n",
    "                    file.write('')\n",
    " \n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-base', model_max_length=512)\n",
    "    model_evaluation = T5ForConditionalGeneration.from_pretrained('t5-base').to(\"cuda\")\n",
    "    mean_evaluation_score = 0\n",
    "    mean_bert = {}\n",
    "    result = \"\"\n",
    "    for i, data in enumerate(dataloader_tqdm):\n",
    "        (sentence, out, extra) = eval(process_function)(data, model=model)\n",
    "        \n",
    "        if out == 1:\n",
    "            dataloader_tqdm.set_postfix({'status': 'Skipped', 'ID': i})\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            #Passage du transcript dans le modèle\n",
    "            if model == 'T5':\n",
    "                result = T5.generate_text(\"grammar:\" + sentence, args=args).text\n",
    "                with open(correction_file, 'a', encoding='utf-8') as file:\n",
    "                    file.write(result + '\\n')\n",
    "                if dataset == 'jfleg':\n",
    "                    with open(vard, 'a', encoding='utf-8') as file:\n",
    "                        file.write(sentence + '\\n')\n",
    "            elif model == 'BART':\n",
    "                result = ''\n",
    "            else:\n",
    "                raise ValueError(f'Unknown model {model}')\n",
    "            \n",
    "            dataloader_tqdm.set_postfix()\n",
    "\n",
    "        except Exception as e:\n",
    "            dataloader_tqdm.set_postfix({'status': 'Error', 'ID': i})\n",
    "            raise e \n",
    "        \n",
    "        # Validation and test with JFLEG\n",
    "        if extra is not None:\n",
    "            best_correction, t5sim, bert_score = evaluate_jfleg(sentence, extra, model_evaluation, tokenizer)\n",
    "            mean_evaluation_score += t5sim\n",
    "            \n",
    "            with open(verification, 'a', encoding='utf-8') as file:\n",
    "                file.write(best_correction[0] + '\\n')\n",
    "            \n",
    "            if bert_score is not None:\n",
    "                for key, value in bert_score.items():\n",
    "                    val = value[0]\n",
    "                    if key not in mean_bert:\n",
    "                        mean_bert[key] = val\n",
    "                    else:\n",
    "                        mean_bert[key] += val\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    mean_evaluation_score /= len(dataloader)\n",
    "    result_test = f'Mean evaluation score: {mean_evaluation_score}\\n'\n",
    "    \n",
    "    for key, value in mean_bert.items():\n",
    "        mean_bert[key] /= len(dataloader)\n",
    "        result_test += f'Mean {key} score: {mean_bert[key]}\\n'\n",
    "    \n",
    "    return result if result != \"\" else result_test\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T04:58:53.828630100Z",
     "start_time": "2023-12-12T04:58:53.816668100Z"
    }
   },
   "id": "45b5c48f45f4e44b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Tests des modèles et des datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a31052a17418fb8a"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 21\n",
      "\n",
      "    Transcript n°0 :\n",
      "    \n",
      "    Transcript : She don't like to eat vegetables.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "892df34c417b4d04a5e38301aab2dc33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating corrections for ASR with T5 in output/T5_ASR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/06/2023 23:58:04 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "HappyTextToText.eval() missing 1 required positional argument: 'input_filepath'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mGEC\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mT5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moutput\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mASR\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[32], line 28\u001B[0m, in \u001B[0;36mGEC\u001B[1;34m(model, output_folder, dataset)\u001B[0m\n\u001B[0;32m     26\u001B[0m mean_evaluation_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     27\u001B[0m mean_evaluation_accuracy \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mT5\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader_tqdm):\n\u001B[0;32m     32\u001B[0m     (sentence, out, extra) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28meval\u001B[39m(process_function)(data, model\u001B[38;5;241m=\u001B[39mmodel)\n",
      "\u001B[1;31mTypeError\u001B[0m: HappyTextToText.eval() missing 1 required positional argument: 'input_filepath'"
     ]
    }
   ],
   "source": [
    "# T5 avec dataset ASR\n",
    "GEC(model='T5', output_folder='output', dataset='ASR')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f53a6e0cb62d5ebc"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 748\n",
      "\n",
      "    Transcript n°0 :\n",
      "\n",
      "    Path audio: data\\\n",
      "    Sentence: New and new technology has been introduced to the society .\n",
      "    Corrections: ['New technology has been introduced to society .', 'New technology has been introduced into the society .', 'Newer and newer technology has been introduced into society .', 'Newer and newer technology has been introduced to the society .']\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/748 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19a9948ded494e47b2db61092a0a4ed7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating corrections for jfleg with T5 in output/T5_jfleg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/11/2023 23:59:26 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "12/11/2023 23:59:33 - INFO - happytransformer.happy_transformer -   Moving model to cuda:0\n",
      "12/11/2023 23:59:33 - INFO - happytransformer.happy_transformer -   Initializing a pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean evaluation score: 4.856417112299462\n",
      "Mean precision score: 0.7269314780114169\n",
      "Mean recall score: 0.7353363115201021\n",
      "Mean f1 score: 0.7309015628328935\n"
     ]
    }
   ],
   "source": [
    "# T5 avec dataset JFLEG\n",
    "GEC(model='T5', output_folder='output', dataset='jfleg')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "514330ac0fc15077"
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Autres tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63092227cb1eca35"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "model_b = T5ForConditionalGeneration.from_pretrained('t5-small').to(\"cuda\")\n",
    "stsb_sentence_1 = preprocess_text\n",
    "stsb_sentence_2 = output\n",
    "input_ids = tokenizer.encode(\"stsb sentence 1: \"+stsb_sentence_1+\" sentence 2: \"+stsb_sentence_2, return_tensors=\"pt\").to(\"cuda\")\n",
    "stsb_ids = model_b.generate(input_ids)\n",
    "stsb = tokenizer.decode(stsb_ids[0],skip_special_tokens=True)\n",
    "print(stsb)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:03:33.541295900Z",
     "start_time": "2023-12-03T22:03:31.450541Z"
    }
   },
   "id": "c05518eae2bd36be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
